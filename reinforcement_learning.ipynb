{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Q-Learning Reinforcement Learning (Frozen Lake)\n",
        "\n",
        "### Dependencies\n",
        "```{bash}\n",
        "pip install \"gym[toy_text]\" numpy\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "slippery = True\n",
        "\n",
        "env = gym.make(\"FrozenLake-v1\", is_slippery=slippery)\n",
        "\n",
        "action_space_size = env.action_space.n # Q-Table columns\n",
        "state_space_size = env.observation_space.n # Q-Table rows\n",
        "\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(q_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_episodes = 10000 # games played\n",
        "max_steps_per_episode = 100 # max step so we don't get stuck\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "# trade off between exploration and exploitation\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001\n",
        "\n",
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state, _ = env.reset()\n",
        "\n",
        "    rewards_current_episode = 0\n",
        "\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Exploration/Exploitation trade off (choose action)\n",
        "        exploration_rate_threshold = random.uniform(0, 1)\n",
        "        if exploration_rate_threshold > exploration_rate:\n",
        "            action = np.argmax(q_table[state]) # exploit\n",
        "        else:\n",
        "            action = env.action_space.sample() # explore\n",
        "\n",
        "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
        "\n",
        "        # Q-Table update formula\n",
        "        q_table[state][action] = q_table[state][action] * (1 - learning_rate) + learning_rate * (reward + discount_rate * np.max(q_table[new_state]))\n",
        "\n",
        "        state = new_state\n",
        "        rewards_current_episode += reward\n",
        "\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    # exploration rate decay\n",
        "    exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
        "\n",
        "    rewards_all_episodes.append(rewards_current_episode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print average reward per 1000 episodes\n",
        "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes), num_episodes/1000)\n",
        "count = 1000\n",
        "print(\"Average reward per thousand episodes\")\n",
        "for r in rewards_per_thousand_episodes:\n",
        "    print(count, \": \", str(sum(r/1000)))\n",
        "    count += 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Q-Table\")\n",
        "print(q_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# play 3 episodes with trained Q-Table\n",
        "env = gym.make(\"FrozenLake-v1\", is_slippery=slippery, render_mode=\"human\")\n",
        "\n",
        "for episode in range(3):\n",
        "    state, _ = env.reset()\n",
        "    print(\"Episode \", episode + 1, \"\\n\\n\\n\")\n",
        "    time.sleep(1)\n",
        "\n",
        "    for step in range(max_steps_per_episode):\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        action = np.argmax(q_table[state,:])\n",
        "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            clear_output(wait=True)\n",
        "            if reward == 1:\n",
        "                print(\"You reached the goal!\")\n",
        "                time.sleep(1)\n",
        "            else:\n",
        "                print(\"You fell through a hole!\")\n",
        "                time.sleep(1)\n",
        "            clear_output(wait=True)\n",
        "            break\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quellen / weiterf√ºhrende Links\n",
        "- [Gymnasium - Frozen Lake Environment](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)\n",
        "- [deeplizard - Reinforcement Learning Series](https://www.youtube.com/watch?v=nyjbcRQ-uQ8&list=PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
